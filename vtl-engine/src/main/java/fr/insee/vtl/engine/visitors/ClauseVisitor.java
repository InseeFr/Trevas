package fr.insee.vtl.engine.visitors;

import static fr.insee.vtl.engine.VtlScriptEngine.fromContext;
import static fr.insee.vtl.engine.utils.TypeChecking.assertBasicScalarType;
import static fr.insee.vtl.engine.utils.TypeChecking.assertNumber;

import fr.insee.vtl.engine.VtlScriptEngine;
import fr.insee.vtl.engine.exceptions.InvalidArgumentException;
import fr.insee.vtl.engine.exceptions.VtlRuntimeException;
import fr.insee.vtl.engine.visitors.expression.ExpressionVisitor;
import fr.insee.vtl.model.*;
import fr.insee.vtl.model.exceptions.VtlScriptException;
import fr.insee.vtl.parser.VtlBaseVisitor;
import fr.insee.vtl.parser.VtlParser;
import java.util.*;
import java.util.stream.Collectors;
import org.antlr.v4.runtime.ParserRuleContext;
import org.antlr.v4.runtime.misc.Interval;

/**
 * <code>ClauseVisitor</code> is the visitor for VTL clause expressions (component filter, aggr,
 * drop, etc.).
 */
public class ClauseVisitor extends VtlBaseVisitor<DatasetExpression> {

  private final DatasetExpression datasetExpression;
  private final ExpressionVisitor componentExpressionVisitor;

  private final ProcessingEngine processingEngine;

  /**
   * Constructor taking a dataset expression and a processing engine.
   *
   * @param datasetExpression The dataset expression containing the clause expression.
   * @param processingEngine The processing engine for dataset expressions.
   */
  public ClauseVisitor(
      DatasetExpression datasetExpression,
      ProcessingEngine processingEngine,
      VtlScriptEngine engine) {
    this.datasetExpression = Objects.requireNonNull(datasetExpression);
    // Here we "switch" to the dataset context.
    Map<String, Object> componentMap =
        datasetExpression.getDataStructure().values().stream()
            .collect(Collectors.toMap(Dataset.Component::getName, component -> component));
    this.componentExpressionVisitor = new ExpressionVisitor(componentMap, processingEngine, engine);
    this.processingEngine = Objects.requireNonNull(processingEngine);
  }

  public static String getName(VtlParser.ComponentIDContext context) {
    // TODO: Should be an expression so we can handle membership better
    //  and use the exceptions for undefined var etc.
    //        res := ds1[calc test := m1 * ds1#m2 + m3]
    //        res := ds1#m1 -> dataset with only m1.
    //        res := ceil(ds1#m1)
    //        res := ceil(ds1)
    String text = context.getText();
    if (text.startsWith("'") && text.endsWith("'")) {
      text = text.substring(1, text.length() - 1);
    }
    return text;
  }

  static String getSource(ParserRuleContext ctx) {
    var stream = ctx.getStart().getInputStream();
    return stream.getText(
        new Interval(ctx.getStart().getStartIndex(), ctx.getStop().getStopIndex()));
  }

  private static AggregationExpression convertToAggregation(
      VtlParser.AggrDatasetContext groupFunctionCtx, ResolvableExpression expression) {
    if (groupFunctionCtx.SUM() != null) {
      var numberExpression = assertNumber(expression, groupFunctionCtx.expr());
      return AggregationExpression.sum(numberExpression);
    } else if (groupFunctionCtx.AVG() != null) {
      var numberExpression = assertNumber(expression, groupFunctionCtx.expr());
      return AggregationExpression.avg(numberExpression);
    } else if (groupFunctionCtx.COUNT() != null) {
      return AggregationExpression.count();
    } else if (groupFunctionCtx.MAX() != null) {
      var typedExpression = assertBasicScalarType(expression, groupFunctionCtx.expr());
      return AggregationExpression.max(typedExpression);
    } else if (groupFunctionCtx.MIN() != null) {
      var typedExpression = assertBasicScalarType(expression, groupFunctionCtx.expr());
      return AggregationExpression.min(typedExpression);
    } else if (groupFunctionCtx.MEDIAN() != null) {
      var numberExpression = assertNumber(expression, groupFunctionCtx.expr());
      return AggregationExpression.median(numberExpression);
    } else if (groupFunctionCtx.STDDEV_POP() != null) {
      var numberExpression = assertNumber(expression, groupFunctionCtx.expr());
      return AggregationExpression.stdDevPop(numberExpression);
    } else if (groupFunctionCtx.STDDEV_SAMP() != null) {
      var numberExpression = assertNumber(expression, groupFunctionCtx.expr());
      return AggregationExpression.stdDevSamp(numberExpression);
    } else if (groupFunctionCtx.VAR_POP() != null) {
      var numberExpression = assertNumber(expression, groupFunctionCtx.expr());
      return AggregationExpression.varPop(numberExpression);
    } else if (groupFunctionCtx.VAR_SAMP() != null) {
      var numberExpression = assertNumber(expression, groupFunctionCtx.expr());
      return AggregationExpression.varSamp(numberExpression);
    } else {
      throw new VtlRuntimeException(
          new VtlScriptException("not implemented", fromContext(groupFunctionCtx)));
    }
  }

  @Override
  public DatasetExpression visitKeepOrDropClause(VtlParser.KeepOrDropClauseContext ctx) {

    // Error reporting context
    final int line = ctx.getStart().getLine();
    final int charPosition = ctx.getStart().getCharPositionInLine();
    final String statement = ctx.getText();

    try {
      // Why is this variable set to 'KEEP'? Where is it suppose to be called the drop function?
      final boolean keep = ctx.op.getType() == VtlParser.KEEP;

      // Columns explicitly requested in the KEEP/DROP clause
      final Set<String> requestedNames =
          ctx.componentID().stream()
              .map(ClauseVisitor::getName)
              .collect(Collectors.toCollection(LinkedHashSet::new)); // preserve user order

      // All available dataset components (ordered as in DataStructure)
      final List<Dataset.Component> componentsInOrder =
          new ArrayList<>(datasetExpression.getDataStructure().values());
      final List<String> allColumnsInOrder =
          componentsInOrder.stream().map(Dataset.Component::getName).collect(Collectors.toList());
      final Set<String> availableColumns = new LinkedHashSet<>(allColumnsInOrder);

      // Dataset identifiers (role = IDENTIFIER)
      final Map<String, Dataset.Component> identifiers =
          componentsInOrder.stream()
              .filter(c -> c.getRole() == Dataset.Role.IDENTIFIER)
              .collect(
                  Collectors.toMap(
                      Dataset.Component::getName, c -> c, (a, b) -> a, LinkedHashMap::new));

      // Evaluate that all requested columns must exist in the dataset or raise an error
      for (String requested : requestedNames) {
        if (!availableColumns.contains(requested)) {
          String errorMsg =
              String.format(
                  "Error: column '%s' not found in dataset. Line %d, position %d. Statement: [%s]",
                  requested, line, charPosition, statement);
          throw new VtlRuntimeException(new InvalidArgumentException(errorMsg, fromContext(ctx)));
        }
      }

      // VTL specification: identifiers must not appear explicitly in KEEP
      final Set<String> forbidden =
          requestedNames.stream()
              .filter(identifiers::containsKey)
              .collect(Collectors.toCollection(LinkedHashSet::new));

      if (!forbidden.isEmpty()) {
        StringBuilder details = new StringBuilder();
        for (String id : forbidden) {
          Dataset.Component comp = identifiers.get(id);
          details.append(
              String.format(
                  "%s(role=%s, type=%s) ",
                  id, comp.getRole(), comp.getType() != null ? comp.getType() : "n/a"));
        }

        String errorMsg =
            String.format(
                "Error: identifiers %s must not be explicitly listed in KEEP/DROP. Line %d, position %d. Statement: [%s]. Details: %s",
                forbidden, line, charPosition, statement, details.toString().trim());
        throw new VtlRuntimeException(new InvalidArgumentException(errorMsg, fromContext(ctx)));
      }

      // Build result set:
      //  + KEEP: identifiers + requested columns
      //  + DROP: (all columns - requested) + identifiers
      final Set<String> resultSet = new LinkedHashSet<>();
      if (keep) {
        resultSet.addAll(identifiers.keySet());
        resultSet.addAll(requestedNames);
      } else {
        for (String col : allColumnsInOrder) {
          if (!requestedNames.contains(col)) {
            resultSet.add(col);
          }
        }
        // Ensure identifiers are always present
        resultSet.addAll(identifiers.keySet());
      }

      // Materialize result respecting dataset structure order
      final List<String> columnNames =
          allColumnsInOrder.stream().filter(resultSet::contains).collect(Collectors.toList());

      return processingEngine.executeProject(datasetExpression, columnNames);

    } catch (VtlRuntimeException e) {
      throw e;
    } catch (Exception e) {
      String errorMsg =
          String.format(
              "Unexpected error while processing KEEP/DROP clause at line %d, position %d. Statement: [%s]. Cause: %s",
              line, charPosition, statement, e.getMessage());
      throw new VtlRuntimeException(new InvalidArgumentException(errorMsg, fromContext(ctx)));
    }
  }

  @Override
  public DatasetExpression visitCalcClause(VtlParser.CalcClauseContext ctx) {

    // Error reporting context
    final int line = ctx.getStart().getLine();
    final int charPosition = ctx.getStart().getCharPositionInLine();
    final String statement = ctx.getText();

    try {

      // Dataset structure (ordered) and quick lookups
      final List<Dataset.Component> componentsInOrder =
          new ArrayList<>(datasetExpression.getDataStructure().values());

      final Map<String, Dataset.Component> byName =
          componentsInOrder.stream()
              .collect(
                  Collectors.toMap(
                      Dataset.Component::getName, c -> c, (a, b) -> a, LinkedHashMap::new));

      // Accumulators for non-analytic calc items
      final LinkedHashMap<String, ResolvableExpression> expressions = new LinkedHashMap<>();
      final LinkedHashMap<String, String> expressionStrings = new LinkedHashMap<>();
      final LinkedHashMap<String, Dataset.Role> roles = new LinkedHashMap<>();

      // Tracks duplicates in the same clause (target names)
      final Set<String> targetsSeen = new LinkedHashSet<>();

      // We need a rolling dataset expression to chain analytics items
      DatasetExpression currentDatasetExpression = datasetExpression;

      // TODO: Refactor so we call executeCalc per CalcClauseItemContext (as analytics do).
      for (VtlParser.CalcClauseItemContext calcCtx : ctx.calcClauseItem()) {

        // ----  Resolve target name and desired role ----
        final String columnName = getName(calcCtx.componentID());
        final Dataset.Role columnRole =
            (calcCtx.componentRole() == null)
                ? Dataset.Role.MEASURE
                : Dataset.Role.valueOf(calcCtx.componentRole().getText().toUpperCase());

        // ---- Validate: duplicate target in the same clause ----
        if (!targetsSeen.add(columnName)) {
          final String errorMsg =
              String.format(
                  "Error: duplicate target '%s' in CALC clause. Line %d, position %d. Statement: [%s]",
                  columnName, line, charPosition, statement);
          throw new VtlRuntimeException(new InvalidArgumentException(errorMsg, fromContext(ctx)));
        }

        // If the target already exists in the dataset, check its role
        final Dataset.Component existing = byName.get(columnName);
        if (existing != null) {
          // Explicitly block overwriting identifiers (already handled above if role==IDENTIFIER).
          if (existing.getRole() == Dataset.Role.IDENTIFIER) {
            final String meta =
                String.format(
                    "(role=%s, type=%s)",
                    existing.getRole(), existing.getType() != null ? existing.getType() : "n/a");
            final String errorMsg =
                String.format(
                    "Error: CALC cannot overwrite IDENTIFIER '%s' %s. Line %d, position %d. Statement: [%s]",
                    columnName, meta, line, charPosition, statement);
            throw new VtlRuntimeException(new InvalidArgumentException(errorMsg, fromContext(ctx)));
          }
        }

        // ---- Dispatch: analytics vs. regular calc ----
        final boolean isAnalytic =
            (calcCtx.expr() instanceof VtlParser.FunctionsExpressionContext)
                && ((VtlParser.FunctionsExpressionContext) calcCtx.expr()).functions()
                    instanceof VtlParser.AnalyticFunctionsContext;

        if (isAnalytic) {
          // Analytics are executed immediately and update the rolling dataset expression
          final AnalyticsVisitor analyticsVisitor =
              new AnalyticsVisitor(processingEngine, currentDatasetExpression, columnName);
          final VtlParser.FunctionsExpressionContext functionExprCtx =
              (VtlParser.FunctionsExpressionContext) calcCtx.expr();
          final VtlParser.AnalyticFunctionsContext anFuncCtx =
              (VtlParser.AnalyticFunctionsContext) functionExprCtx.functions();

          currentDatasetExpression = analyticsVisitor.visit(anFuncCtx);
        } else {
          // Regular calc expression – build resolvable expression and capture its source text
          final ResolvableExpression calc = componentExpressionVisitor.visit(calcCtx);

          final String exprSource = getSource(calcCtx.expr());
          if (exprSource == null || exprSource.isEmpty()) {
            final String errorMsg =
                String.format(
                    "Error: empty or unavailable source expression for '%s' in CALC. Line %d, position %d. Statement: [%s]",
                    columnName, line, charPosition, statement);
            throw new VtlRuntimeException(new InvalidArgumentException(errorMsg, fromContext(ctx)));
          }

          // Store in insertion order (deterministic column creation)
          expressions.put(columnName, calc);
          expressionStrings.put(columnName, exprSource);
          roles.put(columnName, columnRole);
        }
      }

      // ---- Consistency checks before execution ----
      if (!(expressions.keySet().equals(expressionStrings.keySet())
          && expressions.keySet().equals(roles.keySet()))) {
        final String errorMsg =
            String.format(
                "Error: internal CALC maps out of sync (expressions/expressionStrings/roles). Line %d, position %d. Statement: [%s]",
                line, charPosition, statement);
        throw new VtlRuntimeException(new InvalidArgumentException(errorMsg, fromContext(ctx)));
      }

      // ---- Execute the batch calc if any non-analytic expressions were collected ----
      if (!expressionStrings.isEmpty()) {
        currentDatasetExpression =
            processingEngine.executeCalc(
                currentDatasetExpression, expressions, roles, expressionStrings);
      }

      return currentDatasetExpression;

    } catch (VtlRuntimeException e) {
      throw e;
    } catch (Exception e) {
      final String errorMsg =
          String.format(
              "Unexpected error while processing CALC clause at line %d, position %d. Statement: [%s]. Cause: %s",
              line, charPosition, statement, e.getMessage());
      throw new VtlRuntimeException(new InvalidArgumentException(errorMsg, fromContext(ctx)));
    }
  }

  @Override
  public DatasetExpression visitFilterClause(VtlParser.FilterClauseContext ctx) {

    // Error reporting context
    final int line = ctx.getStart().getLine();
    final int charPosition = ctx.getStart().getCharPositionInLine();
    final String statement = ctx.getText();

    try {

      ResolvableExpression filter = componentExpressionVisitor.visit(ctx.expr());
      return processingEngine.executeFilter(datasetExpression, filter, getSource(ctx.expr()));

    } catch (VtlRuntimeException e) {
      throw e;
    } catch (Exception e) {
      String errorMsg =
          String.format(
              "Unexpected error while processing FILTER clause at line %d, position %d. Statement: [%s]. Cause: %s",
              line, charPosition, statement, e.getMessage());
      throw new VtlRuntimeException(new InvalidArgumentException(errorMsg, fromContext(ctx)));
    }
  }

  @Override
  public DatasetExpression visitRenameClause(VtlParser.RenameClauseContext ctx) {

    // Error reporting context
    final int line = ctx.getStart().getLine();
    final int charPosition = ctx.getStart().getCharPositionInLine();
    final String statement = ctx.getText();

    try {

      // Dataset structure in order + lookup maps
      final List<Dataset.Component> componentsInOrder =
          new ArrayList<>(datasetExpression.getDataStructure().values());
      final Set<String> availableColumns =
          componentsInOrder.stream()
              .map(Dataset.Component::getName)
              .collect(Collectors.toCollection(LinkedHashSet::new));

      // Map for detailed error reporting (includes role/type if available)
      final Map<String, Dataset.Component> byName =
          componentsInOrder.stream()
              .collect(
                  Collectors.toMap(
                      Dataset.Component::getName, c -> c, (a, b) -> a, LinkedHashMap::new));

      // Parse the RENAME clause and validate
      Map<String, String> fromTo = new LinkedHashMap<>();
      Set<String> toSeen = new LinkedHashSet<>();
      Set<String> fromSeen = new LinkedHashSet<>();

      for (VtlParser.RenameClauseItemContext renameCtx : ctx.renameClauseItem()) {
        final String toNameString = getName(renameCtx.toName);
        final String fromNameString = getName(renameCtx.fromName);

        // Validate: no duplicate "from" names inside the clause
        if (!fromSeen.add(fromNameString)) {
          String errorMsg =
              String.format(
                  "Error: duplicate source name in RENAME clause: '%s'. Line %d, position %d. Statement: [%s]",
                  fromNameString, line, charPosition, statement);
          throw new VtlRuntimeException(new InvalidArgumentException(errorMsg, fromContext(ctx)));
        }

        // Validate: "from" must exist in dataset
        if (!availableColumns.contains(fromNameString)) {
          Dataset.Component comp = byName.get(fromNameString);
          String meta =
              (comp != null)
                  ? String.format(
                      " (role=%s, type=%s)",
                      comp.getRole(), comp.getType() != null ? comp.getType() : "n/a")
                  : "";
          String errorMsg =
              String.format(
                  "Error: source column to rename not found: '%s'%s. Line %d, position %d. Statement: [%s]",
                  fromNameString, meta, line, charPosition, statement);
          throw new VtlRuntimeException(new InvalidArgumentException(errorMsg, fromContext(ctx)));
        }

        // Validate: no duplicate "to" names inside the clause
        if (!toSeen.add(toNameString)) {
          String errorMsg =
              String.format(
                  "Error: duplicate output column name in RENAME clause: '%s'. Line %d, position %d. Statement: [%s]",
                  fromNameString, line, charPosition, statement);
          throw new VtlRuntimeException(new InvalidArgumentException(errorMsg, fromContext(ctx)));
        }

        fromTo.put(fromNameString, toNameString);
      }

      // Validate collisions with untouched dataset columns ("Untouched" = columns that are not
      // being renamed)
      final Set<String> untouched =
          availableColumns.stream()
              .filter(c -> !fromTo.containsKey(c))
              .collect(Collectors.toCollection(LinkedHashSet::new));

      for (Map.Entry<String, String> e : fromTo.entrySet()) {
        final String from = e.getKey();
        final String to = e.getValue();

        // If target already exists as untouched, it would cause a collision
        if (untouched.contains(to)) {
          Dataset.Component comp = byName.get(to);
          String meta =
              (comp != null)
                  ? String.format(
                      " (role=%s, type=%s)",
                      comp.getRole(), comp.getType() != null ? comp.getType() : "n/a")
                  : "";
          String errorMsg =
              String.format(
                  "Error: target name '%s'%s already exists in dataset and is not being renamed. "
                      + "Line %d, position %d. Statement: [%s]",
                  to, meta, line, charPosition, statement);
          throw new VtlRuntimeException(new InvalidArgumentException(errorMsg, fromContext(ctx)));
        }
      }

      // Execute rename in processing engine
      return processingEngine.executeRename(datasetExpression, fromTo);

    } catch (VtlRuntimeException e) {
      throw e;
    } catch (Exception e) {
      String errorMsg =
          String.format(
              "Unexpected error while processing RENAME clause at line %d, position %d. Statement: [%s]. Cause: %s",
              line, charPosition, statement, e.getMessage());
      throw new VtlRuntimeException(new InvalidArgumentException(errorMsg, fromContext(ctx)));
    }
  }

  @Override
  public DatasetExpression visitAggrClause(VtlParser.AggrClauseContext ctx) {

    // Normalize the dataset so the expressions are removed from the aggregations.
    var aggregationsWithExpressions =
        ctx.aggregateClause().aggrFunctionClause().stream()
            .filter(agg -> agg.aggrOperatorsGrouping() instanceof VtlParser.AggrDatasetContext)
            .collect(Collectors.toList());

    Map<String, ResolvableExpression> expressions =
        aggregationsWithExpressions.stream()
            .collect(
                Collectors.toMap(
                    agg -> getName(agg.componentID()),
                    agg ->
                        componentExpressionVisitor.visit(
                            ((VtlParser.AggrDatasetContext) agg.aggrOperatorsGrouping()).expr())));
    Map<String, Dataset.Role> roles =
        aggregationsWithExpressions.stream()
            .collect(
                Collectors.toMap(
                    agg -> getName(agg.componentID()),
                    agg ->
                        agg.componentRole() == null
                            ? Dataset.Role.MEASURE
                            : Dataset.Role.valueOf(agg.componentRole().getText().toUpperCase())));
    Map<String, String> expressionStrings =
        aggregationsWithExpressions.stream()
            .collect(
                Collectors.toMap(
                    agg -> getName(agg.componentID()),
                    agg -> getSource(agg.aggrOperatorsGrouping())));

    var dataStructure = datasetExpression.getDataStructure();

    DatasetExpression normalizedDataset =
        processingEngine.executeCalc(this.datasetExpression, expressions, roles, expressionStrings);

    // Execute the group all as a calc.
    List<String> groupBy = new ArrayList<>();
    var groupAll = new GroupAllVisitor(componentExpressionVisitor).visit(ctx);
    if (groupAll != null) {
      // TODO, use the name? What if the expression uses multiple columns.
      normalizedDataset =
          processingEngine.executeCalc(
              normalizedDataset,
              Map.of("time", groupAll),
              Map.of("time", Dataset.Role.IDENTIFIER),
              Map.of());
      groupBy.add("time");
    }

    // TODO: Move to engine
    Structured.DataStructure normalizedStructure = normalizedDataset.getDataStructure();

    // Transform column roles into IDENTIFIER when defined in groupingClause
    groupBy.addAll(new GroupByVisitor(dataStructure).visit(ctx));
    normalizedStructure.forEach(
        (k, v) -> {
          if (groupBy.contains(k)) {
            normalizedStructure.put(
                k, new Structured.Component(k, v.getType(), Dataset.Role.IDENTIFIER));
          }
        });

    Map<String, AggregationExpression> collectorMap = new LinkedHashMap<>();
    for (VtlParser.AggrFunctionClauseContext functionCtx :
        ctx.aggregateClause().aggrFunctionClause()) {
      String alias = getName(functionCtx.componentID());
      // TODO: Refactor to avoid this if
      if (normalizedStructure.containsKey(alias)) {
        Structured.Component normalizedComponent = normalizedStructure.get(alias);
        var aggregationFunction =
            convertToAggregation(
                // Note that here we replace the expression by the name of the columns.
                (VtlParser.AggrDatasetContext) functionCtx.aggrOperatorsGrouping(),
                new ResolvableExpression(fromContext(ctx)) {
                  @Override
                  public Object resolve(Map<String, Object> context) {
                    return context.get(alias);
                  }

                  @Override
                  public Class<?> getType() {
                    return normalizedComponent.getType();
                  }
                });
        collectorMap.put(alias, aggregationFunction);
      } else {
        collectorMap.put(alias, AggregationExpression.count());
      }
    }

    return processingEngine.executeAggr(normalizedDataset, groupBy, collectorMap);
  }

  @Override
  public DatasetExpression visitPivotOrUnpivotClause(VtlParser.PivotOrUnpivotClauseContext ctx) {
    if (ctx.op.equals(ctx.UNPIVOT())) {
      throw new UnsupportedOperationException("unpivot is not supported");
    }
    String id = ctx.id_.getText();
    if (!datasetExpression.getIdentifierNames().contains(id)) {
      throw new VtlRuntimeException(
          new InvalidArgumentException(
              id + " is not part of the dataset identifiers", fromContext(ctx.id_)));
    }
    String me = ctx.mea.getText();
    if (!datasetExpression.getMeasureNames().contains(me)) {
      throw new VtlRuntimeException(
          new InvalidArgumentException(
              me + " is not part of the dataset measures", fromContext(ctx.mea)));
    }
    Positioned pos = fromContext(ctx);
    return processingEngine.executePivot(datasetExpression, id, me, pos);
  }
}
