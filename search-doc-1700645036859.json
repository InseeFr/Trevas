[{"title":"Trevas Batch 0.1.1","type":0,"sectionRef":"#","url":"/Trevas/blog/trevas-batch-0.1.1","content":"","keywords":"","version":null},{"title":"Launch​","type":1,"pageTitle":"Trevas Batch 0.1.1","url":"/Trevas/blog/trevas-batch-0.1.1#launch","content":"Local​ java -jar trevas-batch-0.1.1.jar -Dconfig.path=&quot;...&quot; -Dreport.path=&quot;...&quot;  The java execution will be done in local Spark. Kubernetes​ Default Kubernetes objects are defined in the .kubernetes folder. Feed the config-map.yml file then launch the job in your cluster. ","version":null,"tagName":"h3"},{"title":"Trevas Lab 0.3.3","type":0,"sectionRef":"#","url":"/Trevas/blog/trevas-lab-0.3.3","content":"","keywords":"","version":null},{"title":"News​","type":1,"pageTitle":"Trevas Lab 0.3.3","url":"/Trevas/blog/trevas-lab-0.3.3#news","content":"In addition to the VTL coverage greatly increased since the publication of Trevas 1.x.x, Trevas Lab offers 2 new connectors: SAS filesJDBC MariaDB ","version":null,"tagName":"h3"},{"title":"Launch​","type":1,"pageTitle":"Trevas Lab 0.3.3","url":"/Trevas/blog/trevas-lab-0.3.3#launch","content":"Kubernetes​ Sample Kubernetes objects are available in the .kubernetes folders of Trevas Lab and Trevas Lab UI. ","version":null,"tagName":"h3"},{"title":"Trevas Jupyter 0.3.2","type":0,"sectionRef":"#","url":"/Trevas/blog/trevas-jupyter-0.3.2","content":"","keywords":"","version":null},{"title":"News​","type":1,"pageTitle":"Trevas Jupyter 0.3.2","url":"/Trevas/blog/trevas-jupyter-0.3.2#news","content":"In addition to the VTL coverage greatly increased since the publication of Trevas 1.x.x, Trevas Jupyter offers 1 new connector: SAS files (via the loadSas method) ","version":null,"tagName":"h3"},{"title":"Launch​","type":1,"pageTitle":"Trevas Jupyter 0.3.2","url":"/Trevas/blog/trevas-jupyter-0.3.2#launch","content":"Manually adding the Trevas Kernel to an existing Jupyter instance​ Trevas Jupyter compilerCopy the kernel.json file and the bin and repo folders to a new kernel folder.Edit the kernel.json fileLaunch Jupyter Docker​ docker pull inseefrlab/trevas-jupyter:0.3.2 docker run -p 8888:8888 inseefrlab/trevas-jupyter:0.3.2  Helm​ The Trevas Jupyter docker image can be instantiated via the jupyter-pyspark Helm contract from InseeFrLab. ","version":null,"tagName":"h3"},{"title":"Trevas 1.1.0","type":0,"sectionRef":"#","url":"/Trevas/blog/trevas-1.1.0","content":"","keywords":"","version":null},{"title":"News​","type":1,"pageTitle":"Trevas 1.1.0","url":"/Trevas/blog/trevas-1.1.0#news","content":"Trevas 1.1.0 includes hierarchical validation via operators define hierarchical ruleset and check_hierarchy. ","version":null,"tagName":"h3"},{"title":"Example​","type":1,"pageTitle":"Trevas 1.1.0","url":"/Trevas/blog/trevas-1.1.0#example","content":"Input​ ds1: id\tMeABC\t12 A\t1 B\t10 C\t1 DEF\t100 E\t99 F\t1 HIJ\t100 H\t99 I\t0 VTL script​ // Ensure ds1 metadata definition is good ds1 := ds1[calc identifier id := id, Me := cast(Me, integer)]; // Define hierarchical ruleset define hierarchical ruleset hr (variable rule Me) is My_Rule : ABC = A + B + C errorcode &quot;ABC is not sum of A,B,C&quot; errorlevel 1; DEF = D + E + F errorcode &quot;DEF is not sum of D,E,F&quot;; HIJ : HIJ = H + I - J errorcode &quot;HIJ is not H + I - J&quot; errorlevel 10 end hierarchical ruleset; // Check hierarchy ds_all := check_hierarchy(ds1, hr rule id all); ds_all_measures := check_hierarchy(ds1, hr rule id always_null all_measures); ds_invalid := check_hierarchy(ds1, hr rule id always_zero invalid);  Outputs​ ds_all id\truleid\tbool_var\terrorcode\terrorlevel\timbalanceABC\tMy_Rule\ttrue\tnull\tnull\t0 ds_always_null_all_measures id\tMe\truleid\tbool_var\terrorcode\terrorlevel\timbalanceABC\t12\tMy_Rule\ttrue\tnull\tnull\t0 DEF\t100\thr_2\tnull\tnull\tnull\tnull HIJ\t100\tHIJ\tnull\tnull\tnull\tnull ds_invalid id\tMe\truleid\terrorcode\terrorlevel\timbalanceHIJ\t100\tHIJ\tHIJ is not H + I - J\t10\t1 ","version":null,"tagName":"h3"},{"title":"Modifications of VTL grammar","type":0,"sectionRef":"#","url":"/Trevas/administrator-guide/grammar","content":"","keywords":"","version":"Next"},{"title":"Usage of the VTL grammar​","type":1,"pageTitle":"Modifications of VTL grammar","url":"/Trevas/administrator-guide/grammar#usage-of-the-vtl-grammar","content":"Trevas on the VTL formal grammar expressed with EBNF. The reference is the version 2.0 upgrade published in July 2020 on the SDMX web site. The grammar consists of two files ready to be processed by the Antlr parser generator: VtlTokens.g4 contains the list of valid VTL terms. Vtl.g4 contains the rules that produce valid VTL expressions. Antlr uses these files to produce a lexer that creates a list of vocabulary symbols from an input character stream, and a parser that creates the grammatical structure corresponding to this list of symbols. Antlr can generate parsers usable in different target languages. Trevas uses the Java parser, which is exposed in the vtl-parser module. ","version":"Next","tagName":"h2"},{"title":"Adaptations of the grammar​","type":1,"pageTitle":"Modifications of VTL grammar","url":"/Trevas/administrator-guide/grammar#adaptations-of-the-grammar","content":"In order to improve performance and functionalities, minor modifications were made to the VTL grammar used in Trevas. Simplification of the grammatical tree​ As documented here and here, the expr and exprComp branches of the grammatical tree are nearly identical. In order to avoid implementing the same logic twice, the exprComp branch was commented out in the 498c1f8 commit. It was then noticed that this modification wrongly invalidated the COUNT() expression, and the corresponding rule was therefore reactivated in the grammar with the [54f86f2] (https://github.com/InseeFr/Trevas/commit/54f86f27d2e8fdd57df1439d74ed56d225064a7d) commit. Addition of distance operators​ Distance operators like Levenshtein of Jaro-Winkler are commonly used in tests of character strings. In order to allow them in VTL expressions, the 036dc60 commit added to the grammar a distanceOperators section containing a LEVENSHTEIN rule, as well as the LEVENSHTEIN symbol in the lexer file. ","version":"Next","tagName":"h3"},{"title":"Basic mode - Data sources","type":0,"sectionRef":"#","url":"/Trevas/developer-guide/basic-mode/data-sources","content":"","keywords":"","version":"Next"},{"title":"Trevas good practices​","type":1,"pageTitle":"Basic mode - Data sources","url":"/Trevas/developer-guide/basic-mode/data-sources#trevas-good-practices","content":"The JSON format is the only one allowing to store and manage VTL metadata when the Trevas engine is instantiated in basic mode. It is thus strongly recommended to use this format. JDBC JSON Others ","version":"Next","tagName":"h3"},{"title":"Basic mode","type":0,"sectionRef":"#","url":"/Trevas/developer-guide/basic-mode","content":"","keywords":"","version":"Next"},{"title":"InMemoryDataset​","type":1,"pageTitle":"Basic mode","url":"/Trevas/developer-guide/basic-mode#inmemorydataset","content":"The InMemoryDataset datasets can represent statistical tables in a Java application. ","version":"Next","tagName":"h3"},{"title":"Example​","type":1,"pageTitle":"Basic mode","url":"/Trevas/developer-guide/basic-mode#example","content":"ScriptEngine engine = new ScriptEngineManager().getEngineByName(&quot;vtl&quot;); Bindings bindings = new SimpleBindings(); InMemoryDataset dataset = new InMemoryDataset( List.of( Map.of(&quot;var1&quot;, &quot;x&quot;, &quot;var2&quot;, &quot;y&quot;, &quot;var3&quot;, 5), Map.of(&quot;var1&quot;, &quot;xx&quot;, &quot;var2&quot;, &quot;yy&quot;, &quot;var3&quot;, 10) ), Map.of(&quot;var1&quot;, String.class, &quot;var2&quot;, String.class, &quot;var3&quot;, Long.class), Map.of(&quot;var1&quot;, Role.IDENTIFIER, &quot;var2&quot;, Role.ATTRIBUTE, &quot;var3&quot;, Role.MEASURE) ); bindings.put(&quot;myDataset&quot;, dataset); engine.getContext().setBindings(bindings, ScriptContext.ENGINE_SCOPE); String script = &quot;res := myDataset[filter var3 &gt; 6];&quot;; try { engine.eval(script); } catch (ScriptException e) { e.printStackTrace(); } Bindings outputBindings = engine.getContext().getBindings(ScriptContext.ENGINE_SCOPE); InMemoryDataset result = (InMemoryDataset) outputBindings.get(&quot;res&quot;); System.out.println(result.getDataPoints().size()); // 1  ","version":"Next","tagName":"h3"},{"title":"Basic mode - JDBC source","type":0,"sectionRef":"#","url":"/Trevas/developer-guide/basic-mode/data-sources/jdbc","content":"","keywords":"","version":"Next"},{"title":"Import Trevas JDBC module​","type":1,"pageTitle":"Basic mode - JDBC source","url":"/Trevas/developer-guide/basic-mode/data-sources/jdbc#import-trevas-jdbc-module","content":"&lt;dependency&gt; &lt;groupId&gt;fr.insee.trevas&lt;/groupId&gt; &lt;artifactId&gt;vtl-jdbc&lt;/artifactId&gt; &lt;version&gt;1.1.1&lt;/version&gt; &lt;/dependency&gt;  ","version":"Next","tagName":"h3"},{"title":"Usage of the vtl-jdbc module​","type":1,"pageTitle":"Basic mode - JDBC source","url":"/Trevas/developer-guide/basic-mode/data-sources/jdbc#usage-of-the-vtl-jdbc-module","content":"connection = DriverManager.getConnection(...); Statement statement = connection.createStatement(); JDBCDataset jdbcDataset = new JDBCDataset(() -&gt; { try { return statement.executeQuery(&quot;select * from ds1;&quot;); } catch (SQLException se) { throw new RuntimeException(se); } });  ","version":"Next","tagName":"h3"},{"title":"Developer guide","type":0,"sectionRef":"#","url":"/Trevas/developer-guide","content":"","keywords":"","version":"Next"},{"title":"Import the Trevas engine​","type":1,"pageTitle":"Developer guide","url":"/Trevas/developer-guide#import-the-trevas-engine","content":"&lt;dependency&gt; &lt;groupId&gt;fr.insee.trevas&lt;/groupId&gt; &lt;artifactId&gt;vtl-engine&lt;/artifactId&gt; &lt;version&gt;1.1.1&lt;/version&gt; &lt;/dependency&gt;  ","version":"Next","tagName":"h3"},{"title":"Instantiate the Trevas engine​","type":1,"pageTitle":"Developer guide","url":"/Trevas/developer-guide#instantiate-the-trevas-engine","content":"// Start engine ScriptEngine engine = new ScriptEngineManager().getEngineByName(&quot;vtl&quot;); // Add input bindings to engine Bindings bindings = new SimpleBindings(); InMemoryDataset dataset = new InMemoryDataset( List.of( Map.of(&quot;var1&quot;, &quot;x&quot;, &quot;var2&quot;, &quot;y&quot;, &quot;var3&quot;, 5), Map.of(&quot;var1&quot;, &quot;xx&quot;, &quot;var2&quot;, &quot;yy&quot;, &quot;var3&quot;, 10) ), Map.of(&quot;var1&quot;, String.class, &quot;var2&quot;, String.class, &quot;var3&quot;, Long.class), Map.of(&quot;var1&quot;, Role.IDENTIFIER, &quot;var2&quot;, Role.ATTRIBUTE, &quot;var3&quot;, Role.MEASURE) ); bindings.put(&quot;a&quot;, 1); bindings.put(&quot;ds&quot;, dataset); engine.setBindings(b, ScriptContext.ENGINE_SCOPE); // Execute script try { engine.eval(&quot;b := a + 1; &quot; + &quot;ds1 := ds;&quot; + &quot;ds2 &lt;- ds;&quot;); } catch (VtlScriptException e) { logger.warn(&quot;Eval failed: &quot;, e); } // Get result Long result = (Long) engine.getBindings(ScriptContext.ENGINE_SCOPE).get(&quot;b&quot;); Dataset ds1 = (Dataset) engine.getBindings(ScriptContext.ENGINE_SCOPE).get(&quot;ds1&quot;); PersistentDataset result = (PersistentDataset) engine.getBindings(ScriptContext.ENGINE_SCOPE).get(&quot;ds2&quot;);  ","version":"Next","tagName":"h3"},{"title":"Execution mode​","type":1,"pageTitle":"Developer guide","url":"/Trevas/developer-guide#execution-mode","content":"Basic mode Spark mode ","version":"Next","tagName":"h3"},{"title":"Basic mode - JSON source","type":0,"sectionRef":"#","url":"/Trevas/developer-guide/basic-mode/data-sources/json","content":"","keywords":"","version":"Next"},{"title":"Import Trevas Jackson module​","type":1,"pageTitle":"Basic mode - JSON source","url":"/Trevas/developer-guide/basic-mode/data-sources/json#import-trevas-jackson-module","content":"&lt;dependency&gt; &lt;groupId&gt;fr.insee.trevas&lt;/groupId&gt; &lt;artifactId&gt;vtl-jackson&lt;/artifactId&gt; &lt;version&gt;1.1.1&lt;/version&gt; &lt;/dependency&gt;  ","version":"Next","tagName":"h3"},{"title":"SchEma​","type":1,"pageTitle":"Basic mode - JSON source","url":"/Trevas/developer-guide/basic-mode/data-sources/json#schema","content":"The JSON representation of a Dataset is defined as follows: { &quot;dataStructure&quot;: [ { &quot;name&quot;: &quot;id&quot;, &quot;type&quot;: &quot;STRING&quot;, &quot;role&quot;: &quot;IDENTIFIER&quot; }, { &quot;name&quot;: &quot;x&quot;, &quot;type&quot;: &quot;INTEGER&quot;, &quot;role&quot;: &quot;MEASURE&quot; }, { &quot;name&quot;: &quot;y&quot;, &quot;type&quot;: &quot;FLOAT&quot;, &quot;role&quot;: &quot;MEASURE&quot; } ], &quot;dataPoints&quot;: [ [&quot;0001&quot;, 10, 50.5], [&quot;0002&quot;, 20, -8], [&quot;0003&quot;, 1000, 0], [&quot;0004&quot;, 1, 4.5] ] }  ","version":"Next","tagName":"h3"},{"title":"Usage of the vtl-jackson module​","type":1,"pageTitle":"Basic mode - JSON source","url":"/Trevas/developer-guide/basic-mode/data-sources/json#usage-of-the-vtl-jackson-module","content":"Global declaration​ The module can be globally declared at the scope of the client project. public ObjectMapper objectMapper() { return new ObjectMapper() .registerModule(new TrevasModule()); }  Deserialization example​ ObjectMapper objectMapper = new ObjectMapper(); objectMapper.readValue(json, Dataset.class);  ","version":"Next","tagName":"h3"},{"title":"Basic mode - Other sources","type":0,"sectionRef":"#","url":"/Trevas/developer-guide/basic-mode/data-sources/others","content":"","keywords":"","version":"Next"},{"title":"InMemoryDataset constructor​","type":1,"pageTitle":"Basic mode - Other sources","url":"/Trevas/developer-guide/basic-mode/data-sources/others#inmemorydataset-constructor","content":"InMemoryDataset dataset = new InMemoryDataset( List.of( Map.of(&quot;var1&quot;, &quot;x&quot;, &quot;var2&quot;, &quot;y&quot;, &quot;var3&quot;, 5), Map.of(&quot;var1&quot;, &quot;xx&quot;, &quot;var2&quot;, &quot;yy&quot;, &quot;var3&quot;, 10) ), Map.of(&quot;var1&quot;, String.class, &quot;var2&quot;, String.class, &quot;var3&quot;, Long.class), Map.of(&quot;var1&quot;, Role.IDENTIFIER, &quot;var2&quot;, Role.ATTRIBUTE, &quot;var3&quot;, Role.MEASURE) );  ","version":"Next","tagName":"h3"},{"title":"Spark mode - CSV source","type":0,"sectionRef":"#","url":"/Trevas/developer-guide/spark-mode/data-sources/csv","content":"","keywords":"","version":"Next"},{"title":"Read​","type":1,"pageTitle":"Spark mode - CSV source","url":"/Trevas/developer-guide/spark-mode/data-sources/csv#read","content":"Dataset&lt;Row&gt; sparkDataset = spark.read() .option(&quot;delimiter&quot;, &quot;;&quot;) .option(&quot;header&quot;, &quot;true&quot;) .csv(&quot;folder_path&quot;); SparkDataset dataset = new SparkDataset(sparkDataset);  See all supported options in the official documentation. ","version":"Next","tagName":"h3"},{"title":"Write​","type":1,"pageTitle":"Spark mode - CSV source","url":"/Trevas/developer-guide/spark-mode/data-sources/csv#write","content":"The CSV format is not recommended for writing Trevas Datasets (see here) ","version":"Next","tagName":"h3"},{"title":"Spark mode - JDBC source","type":0,"sectionRef":"#","url":"/Trevas/developer-guide/spark-mode/data-sources/jdbc","content":"","keywords":"","version":"Next"},{"title":"Read​","type":1,"pageTitle":"Spark mode - JDBC source","url":"/Trevas/developer-guide/spark-mode/data-sources/jdbc#read","content":"Dataset&lt;Row&gt; sparkDataset = spark.read() .format(&quot;jdbc&quot;) .option(&quot;url&quot;, &quot;myUrl&quot;) .option(&quot;user&quot;, &quot;myUser&quot;) .option(&quot;password&quot;, &quot;myPwd&quot;) .option(&quot;query&quot;, &quot;myQuery&quot;) .option(&quot;driver&quot;, &quot;org.postgresql.Driver&quot;) .load(); SparkDataset dataset = new SparkDataset(sparkDataset);  In this example, the project must include a dependency to the PostgreSQL driver: &lt;dependency&gt; &lt;groupId&gt;org.postgresql&lt;/groupId&gt; &lt;artifactId&gt;postgresql&lt;/artifactId&gt; &lt;version&gt;42.5.1&lt;/version&gt; &lt;/dependency&gt;  See all supported options in the official documentation. ","version":"Next","tagName":"h3"},{"title":"Write​","type":1,"pageTitle":"Spark mode - JDBC source","url":"/Trevas/developer-guide/spark-mode/data-sources/jdbc#write","content":"Le format JDBC format is not recommended for writing Trevas Datasets (see here) ","version":"Next","tagName":"h3"},{"title":"Spark mode - Data sources","type":0,"sectionRef":"#","url":"/Trevas/developer-guide/spark-mode/data-sources","content":"","keywords":"","version":"Next"},{"title":"Trevas good practices​","type":1,"pageTitle":"Spark mode - Data sources","url":"/Trevas/developer-guide/spark-mode/data-sources#trevas-good-practices","content":"The Apache Parquet format is the only one allowing to store and manage VTL metadata when the Trevas engine is instantiated in Spark mode. It is thus strongly recommended to use this format. ","version":"Next","tagName":"h3"},{"title":"Examples​","type":1,"pageTitle":"Spark mode - Data sources","url":"/Trevas/developer-guide/spark-mode/data-sources#examples","content":"Apache Parquet CSV JDBC Others ","version":"Next","tagName":"h3"},{"title":"Spark mode","type":0,"sectionRef":"#","url":"/Trevas/developer-guide/spark-mode","content":"","keywords":"","version":"Next"},{"title":"SparkDataset​","type":1,"pageTitle":"Spark mode","url":"/Trevas/developer-guide/spark-mode#sparkdataset","content":"The SparkDataset data sets can represent statistical tables in a Java application using Trevas in Spark mode. ","version":"Next","tagName":"h3"},{"title":"Import Trevas Spark module​","type":1,"pageTitle":"Spark mode","url":"/Trevas/developer-guide/spark-mode#import-trevas-spark-module","content":"&lt;dependency&gt; &lt;groupId&gt;fr.insee.trevas&lt;/groupId&gt; &lt;artifactId&gt;vtl-spark&lt;/artifactId&gt; &lt;version&gt;1.1.1&lt;/version&gt; &lt;/dependency&gt;  ","version":"Next","tagName":"h3"},{"title":"Spark session​","type":1,"pageTitle":"Spark mode","url":"/Trevas/developer-guide/spark-mode#spark-session","content":"In order to execute VTL via Trevas in Spark mode, a Spark session must be instantiated. The session can be: locale (execution on the Java server)static (execution on a Spark instance installed on a server beforehand)dynamic (dynamic execution on a Kubernetes cluster) SparkSession spark = SparkSession.builder().master(&quot;local&quot;).getOrCreate();  ","version":"Next","tagName":"h3"},{"title":"Example​","type":1,"pageTitle":"Spark mode","url":"/Trevas/developer-guide/spark-mode#example","content":"ScriptEngine engine = new ScriptEngineManager().getEngineByName(&quot;vtl&quot;); Bindings bindings = new SimpleBindings(); SparkDataset dataset = new SparkDataset(spark.read().parquet(&quot;folder_path&quot;)); bindings.put(&quot;myDataset&quot;, dataset); engine.getContext().setBindings(bindings, ScriptContext.ENGINE_SCOPE); engine.put(&quot;$vtl.engine.processing_engine_names&quot;, &quot;spark&quot;); engine.put(&quot;$vtl.spark.session&quot;, spark); String script = &quot;res := myDataset[filter var3 &gt; 6];&quot;; try { engine.eval(script); } catch (ScriptException e) { e.printStackTrace(); } Bindings outputBindings = engine.getContext().getBindings(ScriptContext.ENGINE_SCOPE); SparkDataset result = (SparkDataset) outputBindings.get(&quot;res&quot;); // Ensure direct resolution because of spark lazy mechanism (performance warning!) InMemoryDataset imResult = new InMemoryDataset( result.getDataPoints(), result.getDataStructure() );  ","version":"Next","tagName":"h3"},{"title":"Distributed execution​","type":1,"pageTitle":"Spark mode","url":"/Trevas/developer-guide/spark-mode#distributed-execution","content":"Whether in static or dynamic mode, the distributed execution of the treatments requires that the executors instantiated by the master be able to solve the VTL processing. It is thus necessary to provide the Trevas jars to the executors via the spark.jars option of the SparkConf object: SparkSession.Builder sparkBuilder = SparkSession.builder() SparkConf conf = new SparkConf(); conf.set(&quot;spark.jars&quot;, String.join(&quot;,&quot;, &quot;/vtl-spark.jar&quot;, &quot;/vtl-model.jar&quot;, &quot;/vtl-parser.jar&quot;, &quot;/vtl-engine.jar&quot;, )); sparkBuilder.config(conf); ... SparkSession spark = sparkBuilder.getOrCreate();  ","version":"Next","tagName":"h3"},{"title":"Execution in a Kubernetes cluster​","type":1,"pageTitle":"Spark mode","url":"/Trevas/developer-guide/spark-mode#execution-in-a-kubernetes-cluster","content":"Many options are detailed in the official documentation Among these, one option is particularly important: the Docker image that will allow executors to resolve VTL processing. A custom image is available here. SparkSession.Builder sparkBuilder = SparkSession.builder() SparkConf conf = new SparkConf(); conf.set(&quot;spark.kubernetes.container.image&quot;, &quot;inseefrlab/spark-hadoop:trevas-0.4.7-spark-3.2.1-hadoop-3.3.1-postgresql-42.3.3-postgis-2021.1.0&quot;); conf.set(&quot;spark.kubernetes.container.pullPolicy&quot;, &quot;IfNotPresent&quot;); sparkBuilder.config(conf); sparkBuilder.master(&quot;k8s://...&quot;) ... SparkSession spark = sparkBuilder.getOrCreate();  ","version":"Next","tagName":"h3"},{"title":"Spark mode - Parquet source","type":0,"sectionRef":"#","url":"/Trevas/developer-guide/spark-mode/data-sources/parquet","content":"","keywords":"","version":"Next"},{"title":"Metadata​","type":1,"pageTitle":"Spark mode - Parquet source","url":"/Trevas/developer-guide/spark-mode/data-sources/parquet#metadata","content":"The metadata of the Parquet data sets are inferred from the schema. Types​ Trevas takes care of the conversion between the Parquet types and the types supported by the Trevas engine. Roles​ The VTL roles are added by Trevas to the Parquet schema, by adding a vtlRole metadata to each field descriptor. By default, the columns without role in the Parquet schema will have a MEASURE role in Trevas. VTL allows to modify roles within scripts (see here) ","version":"Next","tagName":"h3"},{"title":"Read​","type":1,"pageTitle":"Spark mode - Parquet source","url":"/Trevas/developer-guide/spark-mode/data-sources/parquet#read","content":"Dataset&lt;Row&gt; sparkDataset = spark.read().parquet(&quot;folder_path&quot;); SparkDataset dataset = new SparkDataset(sparkDataset);  ","version":"Next","tagName":"h3"},{"title":"Write​","type":1,"pageTitle":"Spark mode - Parquet source","url":"/Trevas/developer-guide/spark-mode/data-sources/parquet#write","content":"// Trevas Spark Dataset SparkDataset dataset = ...; // Spark Dataset Dataset&lt;Row&gt; sparkDataset = dataset.getSparkDataset(); sparkDataset.write() .mode(SaveMode.Overwrite) .parquet(&quot;folder_path&quot;);  ","version":"Next","tagName":"h3"},{"title":"Trevas","type":0,"sectionRef":"#","url":"/Trevas/introduction","content":"","keywords":"","version":"Next"},{"title":"What is VTL?​","type":1,"pageTitle":"Trevas","url":"/Trevas/introduction#what-is-vtl","content":"Business, logical-level and user-friendly language for statisticiansRelies on standard structural metadataInteroperable, platform-agnosticFunctional language, enabling data lineage for more insight and reproductibility ","version":"Next","tagName":"h2"},{"title":"Trevas ecosystem​","type":1,"pageTitle":"Trevas","url":"/Trevas/introduction#trevas-ecosystem","content":" Trevas JupyterTrevas LabTrevas Lab APITrevas Batch ","version":"Next","tagName":"h2"},{"title":"Technical description​","type":1,"pageTitle":"Trevas","url":"/Trevas/introduction#technical-description","content":"Trevas provides VTL engines for different execution contexts, in particular a Java 11 engine and an Apache Spark engine. Trevas engines are based on the JSR 223 specification (Scripting for the Java Platform), which describes the use of scripting languages in Java. ","version":"Next","tagName":"h2"},{"title":"Spark mode - Other sources","type":0,"sectionRef":"#","url":"/Trevas/developer-guide/spark-mode/data-sources/others","content":"","keywords":"","version":"Next"},{"title":"SparkDataset constructor​","type":1,"pageTitle":"Spark mode - Other sources","url":"/Trevas/developer-guide/spark-mode/data-sources/others#sparkdataset-constructor","content":"StructType schema = DataTypes.createStructType(List.of( DataTypes.createStructField(&quot;string&quot;, DataTypes.StringType, false), DataTypes.createStructField(&quot;integer&quot;, DataTypes.LongType, false), DataTypes.createStructField(&quot;boolean&quot;, DataTypes.BooleanType, false), DataTypes.createStructField(&quot;float&quot;, DataTypes.DoubleType, false) )); Dataset&lt;Row&gt; dataFrame = spark.createDataFrame(List.of( RowFactory.create(&quot;string&quot;, 1L, true, 1.5D) ), schema); fr.insee.vtl.model.Dataset sparkDataset = new SparkDataset(dataFrame);  ","version":"Next","tagName":"h3"},{"title":"Other formats supported by Spark​","type":1,"pageTitle":"Spark mode - Other sources","url":"/Trevas/developer-guide/spark-mode/data-sources/others#other-formats-supported-by-spark","content":"See the official documentation ","version":"Next","tagName":"h3"},{"title":"Trevas modules","type":0,"sectionRef":"#","url":"/Trevas/modules","content":"Trevas modules VTL Engine Execution engine and its base Java implementation VTL Parser Parser generated by Antlr from the VTL 2.0 formal grammar VTL Spark Execution of VTL transformations by Spark VTL Model Model defining the objects used in the engine VTL JDBC Tools for the use of SQL data sources VTL Jackson JSON serialization / deserialization of data sets","keywords":"","version":"Next"},{"title":"VTL Engine","type":0,"sectionRef":"#","url":"/Trevas/modules/engine","content":"VTL Engine Execution engine and its base Java implementation.","keywords":"","version":"Next"},{"title":"VTL Jackson","type":0,"sectionRef":"#","url":"/Trevas/modules/jackson","content":"VTL Jackson JSON serialization / deserialization of data sets.","keywords":"","version":"Next"},{"title":"VTL JDBC","type":0,"sectionRef":"#","url":"/Trevas/modules/jdbc","content":"VTL JDBC Tools for the use of SQL data sources.","keywords":"","version":"Next"},{"title":"VTL Parser","type":0,"sectionRef":"#","url":"/Trevas/modules/parser","content":"VTL Parser Parser generated by Antlr from the VTL 2.0 formal grammar.","keywords":"","version":"Next"},{"title":"VTL Model","type":0,"sectionRef":"#","url":"/Trevas/modules/model","content":"VTL Model Model defining the objects used in the engine.","keywords":"","version":"Next"},{"title":"VTL Spark","type":0,"sectionRef":"#","url":"/Trevas/modules/spark","content":"VTL Spark Execution of VTL transformations by Spark.","keywords":"","version":"Next"},{"title":"Trevas releases","type":0,"sectionRef":"#","url":"/Trevas/releases","content":"Trevas releases v1.x.x","keywords":"","version":"Next"},{"title":"Release 1.x.x","type":0,"sectionRef":"#","url":"/Trevas/releases/1.x.x","content":"","keywords":"","version":"Next"},{"title":"Version 1.1.1 - 09/09/23​","type":1,"pageTitle":"Release 1.x.x","url":"/Trevas/releases/1.x.x#version-111---090923","content":"(See technical release on Github) Fix check_hierarchy issues: serialization and possibility to return empty dataset ","version":"Next","tagName":"h2"},{"title":"Version 1.1.0 - 09/01/23​","type":1,"pageTitle":"Release 1.x.x","url":"/Trevas/releases/1.x.x#version-110---090123","content":"(See technical release on Github) Validation: define hierarchical ruleset, check_hierarchy ","version":"Next","tagName":"h2"},{"title":"Version 1.0.2 - 06/30/23​","type":1,"pageTitle":"Release 1.x.x","url":"/Trevas/releases/1.x.x#version-102---063023","content":"(See technical release on Github) Split VTL engine method registrations with 2 methods: registerMethod and registerGlobalMethodFix in / not_in bug with null ","version":"Next","tagName":"h2"},{"title":"Version 1.0.1 - 05/23/23​","type":1,"pageTitle":"Release 1.x.x","url":"/Trevas/releases/1.x.x#version-101---052323","content":"(See technical release on Github) Fix Spark serialization issue in check_datapoint implementation ","version":"Next","tagName":"h2"},{"title":"Version 1.0.0 - 05/12/23​","type":1,"pageTitle":"Release 1.x.x","url":"/Trevas/releases/1.x.x#version-100---051223","content":"(See technical release on Github) Membership: #Validation: check, check_datapointDataset operators (ceil(ds), ds1 &lt; ds2, mod(ds, 5), ...) ","version":"Next","tagName":"h2"},{"title":"VTL - Analytic operators","type":0,"sectionRef":"#","url":"/Trevas/user-guide/coverage/analytic-operators","content":"VTL - Analytic operators Name\tSymbol\tInMemory\tSparkAnalytic invocation ❌\t✔️ Counting the number of data points\tcount\t❌\t✔️ Minimum value\tmin\t❌\t✔️ Maximum value\tmax\t❌\t✔️ Median value\tmedian\t❌\t✔️ Sum\tsum\t❌\t✔️ Average value\tavg\t❌\t✔️ Population standard deviation\tstddev_pop\t❌\t✔️ Sample standard deviation\tstddev_samp\t❌\t✔️ Population variance\tvar_pop\t❌\t✔️ Sample variance\tvar_samp\t❌\t✔️ First value\tfirst_value\t❌\t✔️ Last value\tlast_value\t❌\t✔️ Lag\tlag\t❌\t✔️ lead\tlead\t❌\t✔️ Rank\trank\t❌\t✔️ Ratio to report\tratio_to_report\t❌\t✔️","keywords":"","version":"Next"},{"title":"Trevas VTL coverage","type":0,"sectionRef":"#","url":"/Trevas/user-guide/coverage","content":"Trevas VTL coverage General purpose operators Join operators String operators Numeric operators Comparison operators Boolean operators Time operators Set operators Hierarchical aggregation Aggregate operators Analytic operators Data validation operators Conditional operators Clause operators","keywords":"","version":"Next"},{"title":"VTL - Aggregate operators","type":0,"sectionRef":"#","url":"/Trevas/user-guide/coverage/aggregate-operators","content":"VTL - Aggregate operators Name\tSymbol\tInMemory\tSparkAggregate invocation ✔️\t✔️ Counting the number of data points\tcount\t✔️\t✔️ Minimum value\tmin\t✔️\t✔️ Maximum value\tmax\t✔️\t✔️ Median value\tmedian\t✔️\t✔️ Sum\tsum\t✔️\t✔️ Average value\tavg\t✔️\t✔️ Population standard deviation\tstddev_pop\t✔️\t✔️ Sample standard deviation\tstddev_samp\t✔️\t✔️ Population variance\tvar_pop\t✔️\t✔️ Sample variance\tvar_samp\t✔️\t✔️","keywords":"","version":"Next"},{"title":"VTL - Boolean operators","type":0,"sectionRef":"#","url":"/Trevas/user-guide/coverage/boolean-operators","content":"VTL - Boolean operators Name\tSymbol\tBoolean\tComponent\tDatasetLogical conjunction\tand\t✔️\t✔️\t✔️ Logical disjunction\tor\t✔️\t✔️\t✔️ Exclusive disjunction\txor\t✔️\t✔️\t✔️ Logical negation\tnot\t✔️\t✔️\t✔️","keywords":"","version":"Next"},{"title":"VTL - Data validation operators","type":0,"sectionRef":"#","url":"/Trevas/user-guide/coverage/data-validation-operators","content":"VTL - Data validation operators Name\tSymbol\tSupportedCheck datapoint\tcheck_datapoint\t✔️ Check hierarchy\tcheck_hierarchy\t✔️ Check\tcheck\t✔️","keywords":"","version":"Next"},{"title":"VTL - Conditional operators","type":0,"sectionRef":"#","url":"/Trevas/user-guide/coverage/conditional-operators","content":"VTL - Conditional operators Name\tSymbol\tBoolean\tComponent\tDatasetIf Then Else\tif-then-else\t✔️\t✔️\t✔️ Nvl\tnvl\t✔️\t✔️\t✔️","keywords":"","version":"Next"},{"title":"VTL - Comparison operators","type":0,"sectionRef":"#","url":"/Trevas/user-guide/coverage/comparison-operators","content":"VTL - Comparison operators Name\tSymbol\tScalar\tComponent\tDatasetEqual to\t=\t✔️\t✔️\t✔️ Not equal to\t&lt;&gt;\t✔️\t✔️\t✔️ Greater than\t&gt;\t✔️\t✔️\t✔️ Less than\t&lt;\t✔️\t✔️\t✔️ Greater or equal than\t&gt; =\t✔️\t✔️\t✔️ Less or equal than\t&lt;=\t✔️\t✔️\t✔️ Between\tbetween\t✔️\t✔️\t✔️ Element of\tin / not_in\t✔️\t✔️\t✔️ Match characters\tmatch_characters\t✔️\t✔️\t✔️ Is null\tisnull\t✔️\t✔️\t✔️ Exists in\texists_in\tN/A\tN/A\t❌","keywords":"","version":"Next"},{"title":"VTL - General purpose operators","type":0,"sectionRef":"#","url":"/Trevas/user-guide/coverage/general-operators","content":"VTL - General purpose operators Name\tSymbol\tSupportedParentheses\t( )\t✔️ Persistent assignment\t&lt;-\t✔️ Temporary assignment\t:=\t✔️ Membership\t#\t✔️ User-defined operator call ✔️ Evaluation of an external routine\teval\t❌ Type conversion (string, integer, double, boolean)\tcast\t✔️ Type conversion (others)\tcast\t❌","keywords":"","version":"Next"},{"title":"VTL - Clause operators","type":0,"sectionRef":"#","url":"/Trevas/user-guide/coverage/clause-operators","content":"VTL - Clause operators Name\tSymbol\tInMemory\tSparkFiltering Data Points\tfilter\t✔️\t✔️ Calculation of a Component\tcalc\t✔️\t✔️ Aggregation\taggr\t❌\t✔️ Maintaining Components\tkeep\t✔️\t✔️ Removal of Components\tdrop\t✔️\t✔️ Change of Component name\trename\t✔️\t✔️ Pivoting\tpivot\t❌\t❌ Unpivoting\tunpivot\t❌\t❌ Subspace\tsub\t❌\t❌","keywords":"","version":"Next"},{"title":"VTL - Hierarchical aggregation","type":0,"sectionRef":"#","url":"/Trevas/user-guide/coverage/hierarchical-aggregation","content":"VTL - Hierarchical aggregation Name\tSymbol\tInMemory\tSparkHierarchical roll-up\thierarchy\t❌\t❌","keywords":"","version":"Next"},{"title":"VTL - Numeric operators","type":0,"sectionRef":"#","url":"/Trevas/user-guide/coverage/numeric-operators","content":"VTL - Numeric operators Name\tSymbol\tNumber\tComponent\tDatasetUnary plus\t+\t✔️\t✔️\t✔️ Unary minus\t-\t✔️\t✔️\t✔️ Addition\t+\t✔️\t✔️\t✔️ Subtraction\t-\t✔️\t✔️\t✔️ Multiplication\t*\t✔️\t✔️\t✔️ Division\t/\t✔️\t✔️\t✔️ Concatenation\t||\t✔️\t✔️\t✔️ Modulo\tmod\t✔️\t✔️\t✔️ Rounding\tround\t✔️\t✔️\t✔️ Truncation\ttrunc\t✔️\t✔️\t✔️ Ceiling\tceil\t✔️\t✔️\t✔️ Floor\tfloor\t✔️\t✔️\t✔️ Absolute value\tabs\t✔️\t✔️\t✔️ Exponential\texp\t✔️\t✔️\t✔️ Natural logarithm\tln\t✔️\t✔️\t✔️ Power\tpower\t✔️\t✔️\t✔️ Logarithm\tlog\t✔️\t✔️\t✔️ Square root\tsqrt\t✔️\t✔️\t✔️","keywords":"","version":"Next"},{"title":"VTL - Join operators","type":0,"sectionRef":"#","url":"/Trevas/user-guide/coverage/join-operators","content":"VTL - Join operators Name\tSymbol\tInMemory\tSparkJoin\tinner_join, left_join, full_join, cross_join\t✔️\t✔️","keywords":"","version":"Next"},{"title":"VTL - Set operators","type":0,"sectionRef":"#","url":"/Trevas/user-guide/coverage/set-operators","content":"VTL - Set operators Name\tSymbol\tInMemory\tSparkUnion\tunion\t❌\t✔️ Intersection\tintersect\t❌\t❌ Set difference\tsetdiff\t❌\t❌ Symmetric difference\tsymdiff\t❌\t❌","keywords":"","version":"Next"},{"title":"VTL - Time operators","type":0,"sectionRef":"#","url":"/Trevas/user-guide/coverage/time-operators","content":"VTL - Time operators Name\tSymbol\tTime_period\tComponent\tDatasetPeriod indicator\tperiod_indicator\t❌\t❌\t❌ Fill time series\tfill_time_series\t❌\t❌\t❌ Flow to stock\tflow_to_stock\t❌\t❌\t❌ Stock to flow\tstock_to_flow\t❌\t❌\t❌ Time shift\ttimeshift\t❌\t❌\t❌ Time aggregation\ttime_agg\t❌\t❌\t❌ Actual time\tcurrent_date\t✔️\tN/A\tN/A","keywords":"","version":"Next"},{"title":"VTL - String operators","type":0,"sectionRef":"#","url":"/Trevas/user-guide/coverage/string-operators","content":"VTL - String operators Name\tSymbol\tString\tComponent\tDatasetString concatenation\t||\t✔️\t✔️\t✔️ Whitespace removal\ttrim, rtrim, ltrim\t✔️\t✔️\t✔️ Character case conversion\tupper/lower\t✔️\t✔️\t✔️ Sub-string extraction\tsubstr\t✔️\t✔️\t✔️ String pattern replacement\treplace\t✔️\t✔️\t✔️ String pattern location\tinstr\t✔️\t✔️\t✔️ String length\tlength\t✔️\t✔️\t✔️","keywords":"","version":"Next"},{"title":"Trevas client apps","type":0,"sectionRef":"#","url":"/Trevas/user-guide/vtl/client-apps","content":"Trevas client apps Trevas Jupyter Jupyter Kernel Trevas Lab Web application","keywords":"","version":"Next"},{"title":"Trevas Jupyter","type":0,"sectionRef":"#","url":"/Trevas/user-guide/vtl/client-apps/jupyter","content":"","keywords":"","version":"Next"},{"title":"Sources​","type":1,"pageTitle":"Trevas Jupyter","url":"/Trevas/user-guide/vtl/client-apps/jupyter#sources","content":"Github​ Trevas Jupyter Docker Hub​ Trevas Jupyter ","version":"Next","tagName":"h3"},{"title":"Demo​","type":1,"pageTitle":"Trevas Jupyter","url":"/Trevas/user-guide/vtl/client-apps/jupyter#demo","content":"A video will be coming soon ","version":"Next","tagName":"h3"},{"title":"VTL","type":0,"sectionRef":"#","url":"/Trevas/user-guide/vtl","content":"","keywords":"","version":"Next"},{"title":"Documentation​","type":1,"pageTitle":"VTL","url":"/Trevas/user-guide/vtl#documentation","content":"The VTL documentation is available on the official SDMX web site: User manualReference manual ","version":"Next","tagName":"h2"},{"title":"Datasets​","type":1,"pageTitle":"VTL","url":"/Trevas/user-guide/vtl#datasets","content":"VTL datasets must be described by metadata. The different columns have a type and a role. By default, in Trevas, a column without type or role will be assigned a string type and a measure role. The user will then be able to mutate these attributes in the script, in particular via the calc and cast operators. ","version":"Next","tagName":"h2"},{"title":"Simple example​","type":1,"pageTitle":"VTL","url":"/Trevas/user-guide/vtl#simple-example","content":"Considering ds_1 defined as follows: \tid_1\tid_2\tme_1type\tstring\tstring\tstring role\tidentifier\tidentifier\tmeasure id_1\tid_2\tme_1&quot;75001&quot;\t&quot;75&quot;\t&quot;10&quot; &quot;75002&quot;\t&quot;75&quot;\t&quot;100&quot; &quot;70001&quot;\t&quot;70&quot;\t&quot;5&quot; &quot;70002&quot;\t&quot;70&quot;\t&quot;70&quot; To obbtain the sum of me_1 by id_2, only id_2 has to have the identifier role and me_1 has to have the integer type. The following scipt is thus applied: ds_2 := ds_1[calc measure id_2 := id_2, me_1 := cast(me_1, integer)];  ds_2 is then: \tid_1\tid_2\tme_1type\tstring\tstring\tinteger role\tmeasure\tidentifier\tmeasure id_1\tid_2\tme_1&quot;75001&quot;\t&quot;75&quot;\t10 &quot;75002&quot;\t&quot;75&quot;\t100 &quot;70001&quot;\t&quot;70&quot;\t5 &quot;70002&quot;\t&quot;70&quot;\t70 It is now possible to apply the aggr operator: ds_3 := ds_2[aggr sum_me_1 := sum(me_1) group by id_2];  To obtain ds_3: \tid_2\tsum_me_1type\tstring\tinteger role\tidentifier\tmeasure id_2\tme_1&quot;75&quot;\t110 &quot;70&quot;\t75 ","version":"Next","tagName":"h2"},{"title":"Drop","type":0,"sectionRef":"#","url":"/Trevas/user-guide/vtl/sas-vtl/drop","content":"Drop Sas VTL","keywords":"","version":"Next"},{"title":"Sas vs VTL examples","type":0,"sectionRef":"#","url":"/Trevas/user-guide/vtl/sas-vtl","content":"Sas vs VTL examples Keep Drop Rename","keywords":"","version":"Next"},{"title":"Keep","type":0,"sectionRef":"#","url":"/Trevas/user-guide/vtl/sas-vtl/keep","content":"Keep Sas VTL","keywords":"","version":"Next"},{"title":"Trevas Jupyter","type":0,"sectionRef":"#","url":"/Trevas/user-guide/vtl/client-apps/lab","content":"","keywords":"","version":"Next"},{"title":"Sources​","type":1,"pageTitle":"Trevas Jupyter","url":"/Trevas/user-guide/vtl/client-apps/lab#sources","content":"Github​ Trevas Lab UITrevas LabTrevas Spark Hadoop Docker Hub​ Trevas Lab UITrevas LabTrevas Spark Hadoop ","version":"Next","tagName":"h3"},{"title":"Demo​","type":1,"pageTitle":"Trevas Jupyter","url":"/Trevas/user-guide/vtl/client-apps/lab#demo","content":"A video will be coming soon ","version":"Next","tagName":"h3"},{"title":"Rename","type":0,"sectionRef":"#","url":"/Trevas/user-guide/vtl/sas-vtl/rename","content":"Rename Sas VTL","keywords":"","version":"Next"}]