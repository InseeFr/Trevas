---
id: jdbc
title: Spark 模式 - JDBC数据源
sidebar_label: JDBC数据源
slug: /developer-guide/spark-mode/data-sources/jdbc
custom_edit_url: null
---

import useBaseUrl from '@docusaurus/useBaseUrl';

### 读取JDBC数据源

```java
Dataset<Row> sparkDataset = spark.read()
                    .format("jdbc")
                    .option("url", "myUrl")
                    .option("user", "myUser")
                    .option("password", "myPwd")
                    .option("query", "myQuery")
                    .option("driver", "org.postgresql.Driver")
                    .load();
SparkDataset dataset = new SparkDataset(sparkDataset);
```

在下面的例子中，项目必须包含 postgresql Driver 的依赖
```xml
<dependency>
    <groupId>org.postgresql</groupId>
    <artifactId>postgresql</artifactId>
    <version>42.5.1</version>
</dependency>
```

Voir l'ensemble des options supportées dans la [documentation officielle](https://spark.apache.org/docs/latest/sql-data-sources-jdbc.html#data-source-option).

### 写入

Le format JDBC n'est pas conseillé pour écrire des `Dataset` Trevas (voir <a href={useBaseUrl('/developer-guide/spark-mode/data-sources#bonnes-pratiques-trevas')}>ici</a>)
