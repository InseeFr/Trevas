---
id: jdbc
title: Spark 模式 - JDBC数据源
sidebar_label: JDBC数据源
slug: /developer-guide/spark-mode/data-sources/jdbc
custom_edit_url: null
---

import useBaseUrl from '@docusaurus/useBaseUrl';

### 读取 JDBC 数据源

```java
Dataset<Row> sparkDataset = spark.read()
                    .format("jdbc")
                    .option("url", "myUrl")
                    .option("user", "myUser")
                    .option("password", "myPwd")
                    .option("query", "myQuery")
                    .option("driver", "org.postgresql.Driver")
                    .load();
SparkDataset dataset = new SparkDataset(sparkDataset);
```

在下面的例子中，项目必须包含 postgresql Driver 的依赖

```xml
<dependency>
    <groupId>org.postgresql</groupId>
    <artifactId>postgresql</artifactId>
    <version>42.5.1</version>
</dependency>
```

查看所有支持的选项 [官方文档](https://spark.apache.org/docs/latest/sql-data-sources-jdbc.html#data-source-option).

### 写入

不建议使用 jdbc 格式来编写 Trevas 的`Dataset` (请看 <a href={useBaseUrl('/developer-guide/spark-mode/data-sources#bonnes-pratiques-trevas')}>这里</a>)
