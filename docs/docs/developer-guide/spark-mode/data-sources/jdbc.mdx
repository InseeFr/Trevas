---
id: jdbc
title: Spark mode - JDBC source
sidebar_label: JDBC
slug: /developer-guide/spark-mode/data-sources/jdbc
custom_edit_url: null
---

import useBaseUrl from '@docusaurus/useBaseUrl';

### Read

```java
Dataset<Row> sparkDataset = spark.read()
                    .format("jdbc")
                    .option("url", "myUrl")
                    .option("user", "myUser")
                    .option("password", "myPwd")
                    .option("query", "myQuery")
                    .option("driver", "org.postgresql.Driver")
                    .load();
SparkDataset dataset = new SparkDataset(sparkDataset);
```

In this example, the project must include a dependency to the PostgreSQL driver:
```xml
<dependency>
    <groupId>org.postgresql</groupId>
    <artifactId>postgresql</artifactId>
    <version>42.5.1</version>
</dependency>
```

See all supported options in the [official documentation](https://spark.apache.org/docs/latest/sql-data-sources-jdbc.html#data-source-option).

### Write

Le format JDBC format is not recommended for writing Trevas `Dataset`s (see <a href={useBaseUrl('/developer-guide/spark-mode/data-sources#bonnes-pratiques-trevas')}>here</a>)
